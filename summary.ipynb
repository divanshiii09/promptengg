{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "id": "8cb6037d",
   "metadata": {},
   "outputs": [],
   "source": [
    "import google.generativeai as genai\n",
    "import requests\n",
    "from bs4 import BeautifulSoup\n",
    "import time\n",
    "import textwrap\n",
    "from IPython.display import Markdown, display\n",
    "import sounddevice as sd\n",
    "from scipy.io.wavfile import write\n",
    "from dotenv import load_dotenv\n",
    "import whisper\n",
    "import tempfile\n",
    "import os"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "3656d734",
   "metadata": {},
   "outputs": [],
   "source": [
    "load_dotenv()\n",
    "\n",
    "api_key = os.getenv(\"API_KEY\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 73,
   "id": "5d4d4cee",
   "metadata": {},
   "outputs": [],
   "source": [
    "def wrap_text(text, width=100):\n",
    "    return '\\n'.join(textwrap.wrap(text, width=width))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 74,
   "id": "f7483019",
   "metadata": {},
   "outputs": [],
   "source": [
    "def type_text(text, delay=0.005, width=100):\n",
    "    wrapped = wrap_text(text, width)\n",
    "    for line in wrapped.split('\\n'):\n",
    "        for char in line:\n",
    "            print(char, end='', flush=True)\n",
    "            time.sleep(delay)\n",
    "        print()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 75,
   "id": "ad477633",
   "metadata": {},
   "outputs": [],
   "source": [
    "def extract_text_from_url(url):\n",
    "    response = requests.get(url)\n",
    "    soup = BeautifulSoup(response.content, \"html.parser\")\n",
    "\n",
    "    for tag in soup([\"script\", \"style\", \"img\", \"video\", \"iframe\"]):\n",
    "        tag.decompose()\n",
    "\n",
    "    text = soup.get_text(separator=\"\\n\")\n",
    "    cleaned_text = ' '.join(text.split())\n",
    "    return cleaned_text"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 76,
   "id": "231d4e12",
   "metadata": {},
   "outputs": [],
   "source": [
    "def summarize_with_gemini(text):\n",
    "    model = genai.GenerativeModel(\"models/gemini-1.5-flash\")\n",
    "    prompt = f\"\"\"\n",
    "Please generate a **detailed summary** of the following webpage content:\n",
    "- Use bullet points wherever appropriate.\n",
    "- Include subheadings like 'Overview', 'Key Insights', etc.\n",
    "- Do not mention any images, videos, or links.\n",
    "\n",
    "Text content:\n",
    "{text}\n",
    "\"\"\"\n",
    "    response = model.generate_content(prompt)\n",
    "    return response.text"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 77,
   "id": "5a2f0f06",
   "metadata": {},
   "outputs": [],
   "source": [
    "def pretty_display(summary, url, use_typing=True):\n",
    "    heading_main = \"üìÑ SUMMARY OF THE PAGE\"\n",
    "    source_line = f\"üîó URL Entered: {url}\"\n",
    "\n",
    "    if use_typing:\n",
    "        type_text(heading_main)\n",
    "        type_text(source_line)\n",
    "    else:\n",
    "        display(Markdown(f\"## {heading_main}\"))\n",
    "        display(Markdown(f\"**URL Entered:** {url}\"))\n",
    "\n",
    "    sections = summary.strip().split(\"\\n\\n\")\n",
    "\n",
    "    for section in sections:\n",
    "        lines = section.strip().split(\"\\n\")\n",
    "        if not lines:\n",
    "            continue\n",
    "\n",
    "        heading = lines[0].strip().replace(\":\", \"\").upper()\n",
    "        if use_typing:\n",
    "            type_text(f\"\\nüü© {heading}\")\n",
    "        else:\n",
    "            display(Markdown(f\"### üü© *{heading}*\"))\n",
    "\n",
    "        for line in lines[1:]:\n",
    "            clean_line = line.strip().lstrip(\"*\").strip()\n",
    "            if clean_line:\n",
    "                bullet = f\"- {clean_line}\"\n",
    "                if use_typing:\n",
    "                    type_text(bullet)\n",
    "                else:\n",
    "                    display(Markdown(bullet))\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 78,
   "id": "e3e437f5",
   "metadata": {},
   "outputs": [],
   "source": [
    "def spoken_to_url(text):\n",
    "    replacements = {\n",
    "        \" dot \": \".\",\n",
    "        \" dotcom\": \".com\",\n",
    "        \" slash \": \"/\",\n",
    "        \" forward slash \": \"/\",\n",
    "        \" backslash \": \"\\\\\",\n",
    "        \" colon \": \":\",\n",
    "        \" space \": \"\",\n",
    "        \" dash \": \"-\",\n",
    "        \" underscore \": \"_\"\n",
    "    }\n",
    "    text = text.lower()\n",
    "    for spoken, symbol in replacements.items():\n",
    "        text = text.replace(spoken, symbol)\n",
    "    text = text.replace(\" \", \"\")  # Remove extra spaces\n",
    "    return text\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 79,
   "id": "ec20eb57",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "üéôÔ∏è Speak now...\n",
      "‚úÖ Recording done.\n",
      "üìù Raw Transcription: BBC.com\n",
      "üîó Normalized URL text: bbc.com\n",
      "\n",
      "Fetching content and generating summary from: https://bbc.com \n",
      "\n",
      "üìÑ SUMMARY OF THE PAGE\n",
      "üîó URL Entered: https://bbc.com\n",
      " üü© **OVERVIEW**\n",
      " üü© THIS IS A SUMMARY OF THE BBC NEWS HOMEPAGE, SHOWCASING A SELECTION OF BREAKING NEWS STORIES AND\n",
      "FEATURES ACROSS VARIOUS CATEGORIES.  THE SITE FEATURES SECTIONS DEDICATED TO NEWS (GLOBAL AND\n",
      "REGIONAL), SPORT, BUSINESS, INNOVATION, CULTURE, ARTS, TRAVEL, AND EARTH, ALONG WITH AUDIO AND VIDEO\n",
      "CONTENT.\n",
      " üü© **KEY INSIGHTS (HEADLINES AND NEWS SUMMARIES)**\n",
      " üü© * **POLITICS & WORLD AFFAIRS**  THE DEATH OF A RUSSIAN TRANSPORT MINISTER, HOURS AFTER BEING\n",
      "SACKED BY PRESIDENT PUTIN, IS HIGHLIGHTED AS A WARNING TO THE POLITICAL ELITE.  TRUMP'S POTENTIAL\n",
      "DELAY OF TARIFFS IS DISCUSSED IN THE CONTEXT OF INTERNATIONAL TRADE NEGOTIATIONS.  LEAKED AUDIO\n",
      "SUGGESTS A FORMER BANGLADESH LEADER AUTHORIZED A DEADLY CRACKDOWN ON PROTESTERS.  THE ONGOING\n",
      "ISRAEL-GAZA CONFLICT IS COVERED, FOCUSING ON EFFORTS FOR A CEASEFIRE.  THE IMPACT OF TEXAS FLOODS IS\n",
      "DETAILED, WITH A SIGNIFICANT NUMBER OF PEOPLE STILL MISSING.  CONCERNS ABOUT AIR SAFETY IN INDIA ARE\n",
      "ADDRESSED.  TAIWAN'S MILITARY EXERCISES IN RESPONSE TO CHINA ARE ALSO COVERED.  THE KIDNAPPING OF\n",
      "INDIAN MEN IN MALI IS REPORTED.  ALLEGATIONS OF CHILD ABUSE AT AN AUSTRALIAN CHILDCARE CENTER ARE\n",
      "MENTIONED.\n",
      " üü© * **DOMESTIC NEWS (PRIMARILY US & UK)**  REPORTS DETAIL THE WRONGFUL ACCUSATIONS OF CHILD SEX\n",
      "ABUSE VIOLATIONS AGAINST INSTAGRAM USERS. A MASTERCHEF HOST IS REPORTED TO HAVE BEEN SACKED\n",
      "FOLLOWING ALLEGATIONS OF MISCONDUCT.  THE IMPACT OF TEXAS FLOODS, INCLUDING LOSS OF LIFE AND\n",
      "PROPERTY DAMAGE, IS FEATURED PROMINENTLY.  AN INVESTIGATION INTO A LONDON WAREHOUSE ARSON ATTACK\n",
      "LINKED TO WAGNER GROUP IS DISCUSSED.\n",
      " üü© * **OTHER NEWS**  A REVIEW OF THE SUPERMAN FILM IS INCLUDED.  A FEATURE EXPLORES A SCOTTISH-\n",
      "THEMED TOWN IN ITALY.  AN INVESTIGATION INTO CHINA'S RARE EARTH MINING PRACTICES IS MENTIONED.\n",
      " üü© * **BUSINESS & TECHNOLOGY**  NEWS INCLUDES MUSK'S AI FIRM REMOVING INAPPROPRIATE CHATBOT POSTS,\n",
      "AND THE ANNOUNCEMENT OF POTENTIAL TARIFF HIKES ON COPPER.  THE FORMER UK PRIME MINISTER RISHI\n",
      "SUNAK'S NEW JOB AT GOLDMAN SACHS IS REPORTED.\n",
      " üü© * **CULTURE & ENTERTAINMENT**  COVERAGE INCLUDES A REVIEW OF A FRENCH THRILLER FILM AND A\n",
      "DISCUSSION ON THE LACK OF A #METOO MOVEMENT IN HIP-HOP.\n",
      " üü© * **OTHER SECTIONS** THE WEBSITE ALSO INCLUDES SECTIONS ON SCIENCE & HEALTH, OFFERING GUIDANCE ON\n",
      "HEALTHY BREAD CHOICES.  SECTIONS ON TRAVEL, EARTH (ENVIRONMENTAL NEWS), AND A DEDICATED SECTION FOR\n",
      "PODCASTS AND VIDEO CONTENT.\n",
      " üü© **RECURRING THEMES**\n",
      " üü© * THE IMPACT OF POLITICAL DECISIONS AND INTERNATIONAL RELATIONS ON VARIOUS ASPECTS OF LIFE.\n",
      "- The consequences of natural disasters and climate change.\n",
      "- Issues related to technology and its ethical implications.\n",
      "- Coverage of ongoing conflicts and geopolitical tensions.\n",
      " üü© **OVERALL** THE BBC HOMEPAGE PROVIDES A BROAD RANGE OF NEWS AND FEATURES, COVERING A DIVERSE\n",
      "ARRAY OF TOPICS AND PROVIDING UPDATES ON CURRENT EVENTS GLOBALLY.\n"
     ]
    }
   ],
   "source": [
    "\n",
    "# Record duration in seconds\n",
    "duration = 8 # seconds\n",
    "samplerate = 44100  # Hz\n",
    "\n",
    "print(\"üéôÔ∏è Speak now...\")\n",
    "recording = sd.rec(int(duration * samplerate), samplerate=samplerate, channels=1, dtype='int16')\n",
    "sd.wait()\n",
    "print(\"‚úÖ Recording done.\")\n",
    "\n",
    "# Save to temporary file\n",
    "with tempfile.NamedTemporaryFile(suffix=\".wav\", delete=False) as f:\n",
    "    write(f.name, samplerate, recording)\n",
    "    audio_path = f.name\n",
    "\n",
    "# Load Whisper model\n",
    "model = whisper.load_model(\"base\")  # or \"tiny\", \"small\", \"medium\", \"large\"\n",
    "\n",
    "# Transcribe\n",
    "result = model.transcribe(audio_path)\n",
    "transcribed_text = result[\"text\"].strip()\n",
    "print(\"üìù Raw Transcription:\", transcribed_text)\n",
    "\n",
    "# Convert spoken words to URL\n",
    "normalized_text = spoken_to_url(transcribed_text)\n",
    "print(\"üîó Normalized URL text:\", normalized_text)\n",
    "\n",
    "# Add https:// if missing\n",
    "if not normalized_text.startswith(\"http://\") and not normalized_text.startswith(\"https://\"):\n",
    "    url = \"https://\" + normalized_text\n",
    "else:\n",
    "    url = normalized_text\n",
    "\n",
    "print(\"\\nFetching content and generating summary from:\", url, \"\\n\")\n",
    "\n",
    "try:\n",
    "    text = extract_text_from_url(url)\n",
    "    summary = summarize_with_gemini(text)\n",
    "    pretty_display(summary, url, use_typing=True)\n",
    "except Exception as e:\n",
    "    print(\"‚ùå Error fetching or summarizing content:\", e)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 36,
   "id": "0f98adc6",
   "metadata": {},
   "outputs": [],
   "source": [
    "import os"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 37,
   "id": "463f5188",
   "metadata": {},
   "outputs": [],
   "source": [
    "def save_summary_to_markdown(summary, filename=\"summary.md\"):\n",
    "    with open(filename, \"w\", encoding=\"utf-8\") as md_file:\n",
    "        md_file.write(\"# Website Summary\\n\\n\")\n",
    "        md_file.write(summary)\n",
    "    print(\"‚úÖ Summary saved at:\", os.path.abspath(\"summary.md\"))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 38,
   "id": "b0a97947",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "‚úÖ Summary saved at: c:\\Users\\Naman Goyal\\OneDrive\\Desktop\\urlSummary\\Summarizer\\summary.md\n"
     ]
    }
   ],
   "source": [
    "save_summary_to_markdown(summary)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "f83d6996",
   "metadata": {},
   "outputs": [],
   "source": [
    "def search_keyword_in_summary(keyword, summary_file=\"summary.md\", original_text=None):\n",
    "    keyword = keyword.lower()\n",
    "    found_lines = []\n",
    "\n",
    "    try:\n",
    "        with open(summary_file, \"r\", encoding=\"utf-8\") as md_file:\n",
    "            lines = md_file.readlines()\n",
    "            for line in lines:\n",
    "                if keyword in line.lower():\n",
    "                    found_lines.append(line.strip())\n",
    "\n",
    "        if found_lines:\n",
    "            print(f\"\\nüîç Keyword *{keyword}* found in summary:\\n\")\n",
    "            for match in found_lines:\n",
    "                print(\"‚Ä¢\", match)\n",
    "            return\n",
    "\n",
    "        print(f\"‚ùå Keyword '{keyword}' not found in summary. Searching original content...\")\n",
    "\n",
    "    except FileNotFoundError:\n",
    "        print(\"‚ö† Summary file not found. Skipping summary search.\")\n",
    "\n",
    "    if original_text:\n",
    "        if keyword in original_text.lower():\n",
    "            print(f\"\\nüîç Keyword *{keyword}* found in original page content.\\n\")\n",
    "            print(f\"‚úÖ Keyword '{keyword}' is present in the original URL content.\")\n",
    "        else:\n",
    "            print(f\"‚ùå The keyword '{keyword}' was not found in the summary or original URL content.\")\n",
    "    else:\n",
    "        print(\"‚ö† Original text not provided, so could not search beyond summary.\")\n",
    "\n",
    "        \n",
    "def get_voice_input(duration=3, retries=2):\n",
    "    for attempt in range(retries + 1):\n",
    "        print(f\"\\nüéôÔ∏è Speak now ({duration} sec)...\")\n",
    "        samplerate = 44100\n",
    "        recording = sd.rec(int(duration * samplerate), samplerate=samplerate, channels=1, dtype='int16')\n",
    "        sd.wait()\n",
    "        print(\"‚úÖ Voice input captured.\")\n",
    "\n",
    "        with tempfile.NamedTemporaryFile(suffix=\".wav\", delete=False) as f:\n",
    "            write(f.name, samplerate, recording)\n",
    "            audio_path = f.name\n",
    "\n",
    "        result = model.transcribe(audio_path)\n",
    "        os.remove(audio_path)\n",
    "\n",
    "        spoken_text = result[\"text\"].strip().lower()\n",
    "        if spoken_text:\n",
    "            print(f\"üó£Ô∏è You said: {spoken_text}\")\n",
    "            return spoken_text\n",
    "        else:\n",
    "            print(\"‚ö†Ô∏è Couldn't understand. Please try speaking again.\")\n",
    "\n",
    "    print(\"‚ùå Failed to capture voice input after multiple attempts.\")\n",
    "    return None\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 62,
   "id": "29e60b4f",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "üéôÔ∏è Speak now (3 sec)...\n",
      "‚úÖ Voice input captured.\n",
      "‚ö†Ô∏è Couldn't understand. Please try speaking again.\n",
      "\n",
      "üéôÔ∏è Speak now (3 sec)...\n",
      "‚úÖ Voice input captured.\n",
      "üó£Ô∏è You said: india\n",
      "\n",
      "üîç Keyword *india* found in summary:\n",
      "\n",
      "‚Ä¢ * **India:**  India's air safety regulator assures that the country's skies remain safe despite rising concerns.\n"
     ]
    }
   ],
   "source": [
    "keyword = get_voice_input(duration=3)\n",
    "\n",
    "if keyword:\n",
    "    search_keyword_in_summary(keyword, summary_file=\"summary.md\", original_text=text)\n",
    "else:\n",
    "    print(\"‚ùå No valid keyword provided. Skipping search.\")\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 54,
   "id": "fc8b2e7a",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "‚úÖ Summary logged to 'history.json'\n"
     ]
    }
   ],
   "source": [
    "import json\n",
    "import os\n",
    "from datetime import datetime\n",
    "\n",
    "def log_summary(source_url, summary_file_path, summary_text=None, model_used=\"Gemini\"):\n",
    "    history_file = \"history.json\"\n",
    "\n",
    "    if os.path.exists(history_file):\n",
    "        try:\n",
    "            with open(history_file, \"r\") as f:\n",
    "                history = json.load(f)\n",
    "            if not isinstance(history, dict):\n",
    "                history = {}\n",
    "        except json.JSONDecodeError:\n",
    "            history = {}\n",
    "    else:\n",
    "        history = {}\n",
    "\n",
    "    summary_entry = {\n",
    "        \"timestamp\": datetime.now().strftime(\"%Y-%m-%d %H:%M:%S\"),\n",
    "        \"source_url\": source_url,\n",
    "        \"summary_file\": os.path.basename(summary_file_path),\n",
    "        \"used_model\": model_used\n",
    "    }\n",
    "\n",
    "    if summary_text:\n",
    "        summary_entry[\"summary_preview\"] = summary_text[:200] + \"...\"\n",
    "\n",
    "    history.setdefault(\"summaries\", []).append(summary_entry)\n",
    "\n",
    "    with open(history_file, \"w\") as f:\n",
    "        json.dump(history, f, indent=4)\n",
    "\n",
    "    print(f\"‚úÖ Summary logged to '{history_file}'\")\n",
    "\n",
    "\n",
    "log_summary(url, \"summary.md\")"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.11.1"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
